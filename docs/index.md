# agentâ€‘generator ğŸ› ï¸ğŸ¤–

*A oneâ€‘line prompt â€¦ a fully configured multiâ€‘agent team.*

![architecture](images/architecture.svg)

`agentâ€‘generator` converts plainâ€‘English requirements into runnable code for:

* **CrewAI** & **CrewAIÂ Flow**
* **LangGraph**
* **ReAct**
* **WatsonXÂ Orchestrate** (YAML)

Highlights:

| Feature                | âœ“ |
|------------------------|---|
| IBMÂ WatsonX *default*  | âœ… |
| Plugâ€‘in providers      | âœ… |
| MCP server wrapper     | âœ… |
| Rich CLI + Flask UI    | âœ… |
| Mermaid / DOT diagrams | âœ… |

<div class="admonition tip">
<strong>Quick install</strong>

```bash
pip install agent-generator
````

</div>

Jump in: **[Installation âœ](installation.md)** Â· **[Usage âœ](usage.md)** Â· **[Frameworks âœ](frameworks.md)**

````

---

### `docs/installation.md`
```markdown
# Installation

## Core (WatsonX only)

```bash
pip install agent-generator
````

## Extras

| Extra tag | Installs                     | Purpose           |
| --------- | ---------------------------- | ----------------- |
| `openai`  | `openai` SDK                 | Use GPT models    |
| `web`     | `flask`, `gunicorn`          | Run the visual UI |
| `dev`     | `pytest`, `ruff`, `mkdocs` â€¦ | Contribute / test |

```bash
# Core + web UI
pip install "agent-generator[web]"

# Everything
pip install "agent-generator[dev,web,openai]"
```

## Environment

Create `.env`â€¯(or export directly):

```bash
# WatsonX (default)
export WATSONX_API_KEY="..."
export WATSONX_PROJECT_ID="..."
export WATSONX_URL="https://us-south.ml.cloud.ibm.com"

# Optional OpenAI
export OPENAI_API_KEY="sk-..."
```

> The CLI will error early if the chosen provider credentials are missing.

````

---

### `docs/usage.md`
```markdown
# Usage

## CLI

```bash
agent-generator "I need a research assistant" \
  --framework crewai \
  --output research_team.py --mcp
````

### Common flags

| Flag               | Meaning                                                          |
| ------------------ | ---------------------------------------------------------------- |
| `-f / --framework` | crewai Â· crewai\_flow Â· langgraph Â· react Â· watsonx\_orchestrate |
| `-p / --provider`  | watsonx *(default)* Â· openai                                     |
| `--mcp`            | Append FastAPI wrapper to Python files                           |
| `--dry-run`        | Donâ€™t call the LLM â€“ scaffold only                               |
| `--show-cost`      | Print token & USD estimate                                       |

---

## Webâ€¯UI

```bash
FLASK_APP=agent_generator.web FLASK_ENV=development flask run
```

* Fill prompt â†’ pick framework â†’ **Generate**
* Download code / YAML or copy to clipboard
* Mermaid diagram autoâ€‘renders below the form

![ui-screenshot](images/ui-screenshot.png)

---

## Docker

```bash
docker build -t agentgen .
docker run -e WATSONX_API_KEY=... -p 8000:8000 agentgen
# UI now at http://localhost:8000
```

````

---

### `docs/frameworks.md`
```markdown
# Framework comparison

This page shows what the same 2â€‘task workflow looks like across all supported targets.

> **Scenario**  
> *Agent A* researches market data â†’ *AgentÂ B* writes a summary.

---

## CrewAI

```python
from crewai import Agent as CrewAgent, Task as CrewTask, Crew

agent_a = CrewAgent(role="researcher", goal="Gather data")
agent_b = CrewAgent(role="writer", goal="Summarise findings")

t1 = CrewTask(description="Research the market", agent=agent_a)
t2 = CrewTask(description="Write a summary",  agent=agent_b)

Crew(agents=[agent_a, agent_b], tasks=[t1, t2]).kickoff()
````

---

## CrewAIÂ Flow (eventâ€‘driven)

```python
from crewai.flow.flow import Flow, start, listen

class State(BaseModel):
    results: dict = {}

class Workflow(Flow[State]):
    @start()
    def research(self): ...
    @listen("research")
    def summarise(self): ...
```

---

## LangGraph

```python
def research(state): ...
def summarise(state): ...

graph = Graph()
graph.add_node("research", research)
graph.add_node("summarise", summarise)
graph.connect("research", "summarise")
graph.set_entry("research")
graph.run({})
```

---

## ReAct

```python
thought = think("Research the market")
result  = act(thought)
print(result)
```

---

## WatsonXÂ Orchestrate (YAML)

```yaml
spec_version: v1
kind: native
name: market-analyst
llm: watsonx/meta-llama-3-70b-instruct
tools:
  - search
  - summarise
...
```

---

## Cost cheatâ€‘sheet *(2025â€‘07â€‘21)*

| Provider | Model                 | Prompt / 1K | Completion / 1K | Comment        |
| -------- | --------------------- | ----------- | --------------- | -------------- |
| WatsonX  | metaâ€‘llamaâ€‘3â€‘70bâ€‘inst | **\$0.003** | **\$0.015**     | default        |
| OpenAI   | gptâ€‘4o                | \$0.01      | \$0.03          | optional extra |

*(Prices subject to change; run `--show-cost` for live estimates.)*

---

### Which should I pick?

| Need                          | Best fit                |
| ----------------------------- | ----------------------- |
| Quick sequential prototype    | **CrewAI**              |
| Eventâ€‘driven with state       | **CrewAIÂ Flow**         |
| Complex DAG, LangChainâ€‘native | **LangGraph**           |
| Simple Reasonâ€‘Act pattern     | **ReAct**               |
| Enterprise workflow           | **WatsonXÂ Orchestrate** |

---

### Visual comparison

```mermaid
graph LR
  A[Research Market] --> B[Write Summary]
```

> The same graph is embedded by default in the WebÂ UI and in generated docs.

````

---

### Adding to `mkdocs.yml` (if you use one)

```yaml
nav:
  - Home: index.md
  - Installation: installation.md
  - Usage: usage.md
  - Frameworks: frameworks.md
````

These four pages give you a **complete MVP documentation set**â€”overview, install guide, handsâ€‘on usage, and an inâ€‘depth framework comparison with diagrams and cost tables.
