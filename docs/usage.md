# Usage Guide

This page covers common workflows for both the **CLI** and the **Flaskâ€¯WebÂ UI**.  
For installation instructions see [Installation](installation.md).

---

## 1Â Â Interactive Wizard (Zeroâ€‘Flag)

Simply running:

```bash
agent-generator
````

without any arguments launches the **guided wizard**:

```text
ğŸª„  Agent Generator â€¢ Guided mode

Describe what youâ€™d like to build:
> A research assistant that can search and read internal PDFs and summarise them.

Choose target framework (default = watsonx_orchestrate):
  1) watsonx_orchestrate
  2) crewai
  3) langraph
  4) beeai
  5) react
Select [1-5]: 1

â³  Contacting backend orchestrator â€¦

ğŸ“‚  Proposed project structure:

  build/
    watsonx_orchestrate/
      agents/research_assistant.yaml
      tool_sources/pdf_summariser/â€¦
      mcp_servers/
        docling_gateway/

Generate this project? [Y/n]: y
ğŸ¤–  Running multi-agent build â€¦
âœ”  pdf_summariser scaffolded
âœ”  agent YAML written
ğŸš€  Done. Created build/watsonx_orchestrate/
```

This flow:

1. **Prompts** for a freeâ€‘text use case
2. **Lets you pick** a framework
3. **Fetches a plan** from the BeeAI backend
4. **Previews** the proposed project tree
5. On **confirmation**, runs the multiâ€‘agent builder to scaffold all code and YAML

---

## 2Â Â Commandâ€‘line Interface (Oneâ€‘Liners)

### 2.1Â `create` Command

For power users, you can skip most prompts with `create`:

```bash
agent-generator create "Research assistant for PDFs" \
  --framework watsonx_orchestrate \
  --build
```

* **`create`** replaces the wizard input with your prompt
* **`--framework`** picks your target
* **`--build`** asks for final confirmation before building

### 2.2Â `generate` Command

To generate code or YAML without scaffolding a full project:

```bash
agent-generator generate "Email summariser" \
  --framework watsonx_orchestrate \
  --output summariser.yaml
```

Or with Python frameworks:

```bash
agent-generator generate "Analyse tweets" \
  --framework crewai \
  --mcp \
  --output tweets_flow.py
```

#### Common flags

| Flag / Option        | Description                                        |
| -------------------- | -------------------------------------------------- |
| `-f, --framework`â€¯\* | Which generator to use (`crewai`, `langgraph`, â€¦). |
| `-p, --provider`     | LLM backâ€‘end (`watsonx` default, or `openai`).     |
| `--model`            | Override default model for the provider.           |
| `--temperature`      | Sampling randomness (0â€“2).                         |
| `--max-tokens`       | Response length cap.                               |
| `--mcp / --no-mcp`   | Wrap Python output in an MCP FastAPI server.       |
| `-o, --output PATH`  | Write result to file instead of stdout.            |
| `--dry-run`          | Build workflow + code skeleton but skip LLM call.  |
| `--show-cost`        | Print token counts & approximate USD cost.         |
| `--version`          | Show CLI version and exit.                         |

---

## 3Â Â Flaskâ€¯WebÂ UI

### 3.1Â Run locally

```bash
FLASK_APP=agent_generator.web FLASK_ENV=development flask run
# visit http://localhost:5000
```

### 3.2Â Workflow

1. **Fill in prompt** â€“ describe your requirement
2. **Pick framework & provider** â€“ dropâ€‘downs
3. *(Optional)* toggle **MCP wrapper**
4. Click **Generate**
5. Download or copyâ€‘paste the code/YAML
6. Mermaid diagram appears under the code for quick validation

![UI screenshot](images/ui-screenshot.png)

---

## 4Â Â Docker Usage

```bash
docker build -t agent-generator .
docker run -e WATSONX_API_KEY=... -e WATSONX_PROJECT_ID=... \
           -p 8000:8000 agent-generator
# Web UI â†’ http://localhost:8000
```

You can also exec into the container to run the CLI:

```bash
docker run --rm agent-generator \
  agent-generator "Say hi" -f react --dry-run
```

---

## 5Â Â Serving Generated MCP Skills

Every Python framework (`crewai`, `crewai_flow`, `langraph`, `react`, `beeai`) can be generated with an **MCP wrapper**:

```bash
agent-generator "...data pipeline..." \
  -f langraph --mcp -o pipeline.py

python pipeline.py serve      # exposes POST /invoke on portÂ 8080
```

Upload the script or Docker image to your MCP Gateway and import it as a custom skill in WatsonXâ€¯Orchestrate.

---

## 6Â Â Troubleshooting

| Symptom                        | Resolution                                                                          |
| ------------------------------ | ----------------------------------------------------------------------------------- |
| *CLI raisesÂ 401* (WatsonX)     | Verify `WATSONX_API_KEY`, `WATSONX_PROJECT_ID`, region URL.                         |
| *`ModuleNotFoundError: flask`* | `pip install "agent-generator[web]"`                                                |
| *Wizard not appearing*         | Run `agent-generator` with no args; ensure `invoke_without_command=True` is active. |
| *High cost estimate*           | Lower `--max-tokens` or pick a smaller model (e.g. `--model llama-3-8b`).           |
| *Gateway import fails*         | Ensure you used `--mcp` and portÂ 8080 is exposed.                                   |

Still stuck?Â Open an issue on the [GitHub tracker](https://github.com/ruslanmv/agent-generator/issues).

Jump in: **[Installation âœ](installation.md)** Â· **[Frameworks âœ](frameworks.md)**
